{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import keras.layers as L\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications import DenseNet121\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 272s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exemplar_set(size, images, trained_model):\n",
    "    #'images' has images all of class=y\n",
    "    for i in images:\n",
    "        exemplars.append(calc_feature_vector(i, trained_model, layer_index))\n",
    "    chosen_exemplars=exemplars[:size]\n",
    "    mean_exemplar=sum(exemplars)/len(images)\n",
    "    return chosen_exemplars, mean_exemplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_loss():\n",
    "    gan_vs_nogan=keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
    "    type_of_gan=keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "    combined_loss=tf.add(gan_vs_nogan, type_of_gan)\n",
    "    return combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes, input_dim):\n",
    "    '''densenet=DenseNet121(include_top=False, \n",
    "                         weights='imagenet', \n",
    "                         input_shape=(input_dim, input_dim,3), \n",
    "                         classes=n_classes)\n",
    "    '''\n",
    "    model=keras.Sequential(\n",
    "    [\n",
    "        L.Conv2D(64, kernel_size=3, padding='same', strides=2, input_shape=(input_dim, input_dim,3)),\n",
    "        L.LeakyReLU(0.2),\n",
    "        L.Conv2D(32, kernel_size=3, padding='same', strides=2),\n",
    "        L.LeakyReLU(0.2),\n",
    "        L.Conv2D(16, kernel_size=3, padding='same', strides=2),\n",
    "        L.LeakyReLU(0.2),\n",
    "        L.Flatten(),\n",
    "        L.Dense(n_classes),\n",
    "        L.Softmax()\n",
    "    ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, n_epochs, x_train, y_train):\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.02), \n",
    "                  loss=keras.losses.CategoricalCrossentropy, \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(x=x_train, \n",
    "              y=y_train, \n",
    "              epochs=n_epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_vector(image, model, layer_index):\n",
    "    #extract feature vector from a layer of ALREADY-TRAINED model\n",
    "    extractor=keras.Model(model.inputs(), [model.layers[layer_index].output])\n",
    "    vector=extractor(image)\n",
    "    #divide vector by norm\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                125450    \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 150,330\n",
      "Trainable params: 150,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=create_model(10, 224)\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

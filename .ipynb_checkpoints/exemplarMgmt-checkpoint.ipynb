{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import keras.layers as L\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications import DenseNet121\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 272s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exemplar_set(size, n, X):\n",
    "    #X has images all of class=y\n",
    "    for i in X:\n",
    "        #obtain feature vectors of all images in set\n",
    "    #stored in 'exemplars'\n",
    "    #choose first n which best represent the class\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes, input_dim):\n",
    "    '''densenet=DenseNet121(include_top=False, \n",
    "                         weights='imagenet', \n",
    "                         input_shape=(input_dim, input_dim,3), \n",
    "                         classes=n_classes)\n",
    "        model=keras.Sequential(\n",
    "    [\n",
    "        L.Conv2D(64, kernel_size=3, padding='same', strides=2, input_shape=(input_dim, input_dim,3)),\n",
    "        L.LeakyReLU(0.2),\n",
    "        L.Conv2D(32, kernel_size=3, padding='same', strides=2),\n",
    "        L.LeakyReLU(0.2),\n",
    "        L.Conv2D(16, kernel_size=3, padding='same', strides=2),\n",
    "        L.LeakyReLU(0.2),\n",
    "        L.Flatten(),\n",
    "        L.Dense(n_classes),\n",
    "        L.Softmax()\n",
    "    ]\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 56, 56, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                125450    \n",
      "_________________________________________________________________\n",
      "softmax_4 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 150,330\n",
      "Trainable params: 150,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=create_model(10, 224)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(X, input_dim, n_classes):\n",
    "    #use a CNN (or any other network) to extract a feature vector from an input image\n",
    "    \n",
    "\n",
    "    \n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

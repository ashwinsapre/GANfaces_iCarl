{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "iCarl_main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinsapre/GANfaces_iCarl/blob/main/iCarl_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y73F_4X-AuAy"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import keras.layers as L\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.applications import DenseNet121\n",
        "from keras.applications import VGG16\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VttqVxphAuA6"
      },
      "source": [
        " For multi-task learning, branching NN out\n",
        "- one branch predicts the class of FashionMNIST object (classification)\n",
        "- other branch predicts whether the object is a \"top\" or not (0/1 output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAzJyR_jyokb"
      },
      "source": [
        "def calc_feature_vectors(model, images):\r\n",
        "    #extract feature vector from a layer of ALREADY-TRAINED model\r\n",
        "    #size of feature vector=784\r\n",
        "    feature_model=keras.Model(inputs=model.inputs, outputs=model.get_layer(\"flatten\").output)\r\n",
        "    feature_vectors=feature_model.predict(images)\r\n",
        "    norms=np.linalg.norm(feature_vectors, keepdims=True, axis=1)\r\n",
        "    feature_vectors=feature_vectors/norms\r\n",
        "    return feature_vectors"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS8E3gY2ytYc"
      },
      "source": [
        "def create_exemplar_set(mem_size, n_classes, feature_vectors, labels, reconstruct=False):\r\n",
        "    per_class=mem_size//n_classes\r\n",
        "\r\n",
        "    class_vectors={}\r\n",
        "    mean_class_vectors={}\r\n",
        "    class_vectors_distances={}\r\n",
        "\r\n",
        "    #init dicts\r\n",
        "    for i in range(n_classes):\r\n",
        "        class_vectors[i]=[]\r\n",
        "        mean_class_vectors[i]=[]\r\n",
        "        class_vectors_distances[i]=[]\r\n",
        "    \r\n",
        "    #vectors belonging to class i go in the list in key i of class_vectors\r\n",
        "    for i in range(len(labels)):\r\n",
        "        class_vectors[labels[i]].append(feature_vectors[i])\r\n",
        "\r\n",
        "    #calculate mean class vectors by summing all vectors per class and diving by length\r\n",
        "    for i in range(n_classes):\r\n",
        "        mean_class_vectors[i]=np.sum(class_vectors[i], axis=0)/len(class_vectors[i])\r\n",
        "    \r\n",
        "    #calculating distances from mean\r\n",
        "    for i in range(len(labels)):\r\n",
        "        class_vectors_distances[labels[i]].append(np.linalg.norm(mean_class_vectors[labels[i]] - feature_vectors[i]))\r\n",
        "\r\n",
        "    #sorting vectors by their corresponding distances from class means\r\n",
        "    for i in range(n_classes):\r\n",
        "        class_vectors_distances[i], class_vectors[i] = (list(t) for t in zip(*sorted(zip(class_vectors_distances[i], class_vectors[i]))))\r\n",
        "\r\n",
        "    exemplars_x = []\r\n",
        "    exemplars_y = []\r\n",
        "\r\n",
        "    #choose 'per_class' number of vectors\r\n",
        "    for i in range(n_classes):\r\n",
        "        exemplars_x.append(class_vectors[i][:per_class])\r\n",
        "        exemplars_y+= per_class*[i]\r\n",
        "\r\n",
        "    return exemplars_x, exemplars_y"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k514jxJ6ywEn"
      },
      "source": [
        "def classify(X, mean_class_vectors, n_classes):\r\n",
        "    #image embedding created\r\n",
        "    image_vector=calc_feature_vectors(model, X)\r\n",
        "    #distance to all mean vectors calculated\r\n",
        "    distances=[]\r\n",
        "    indices=[x for x in range(n_classes)]\r\n",
        "    #sort class values by their corresponding distances\r\n",
        "    for i in range(n_classes):\r\n",
        "        distances.append(np.linalg.norm(mean_class_vectors[i] - image_vector))\r\n",
        "    distances, indices = (list(t) for t in zip(*sorted(zip(distances, indices))))\r\n",
        "    #return the class with the least distance\r\n",
        "    return indices[0]"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-eX21QAuA6"
      },
      "source": [
        "def create_model(n_classes, input_dim, cl_weight, b_weight, lr):\n",
        "    '''\n",
        "        Creating categorical classification model\n",
        "    '''\n",
        "    \n",
        "    inputs=L.Input((input_dim,input_dim,1), name='input_layer_common')\n",
        "    \n",
        "    xc=L.Conv2D(64, kernel_size=3, padding='same', strides=1, name='conv1_c')(inputs)\n",
        "    xc=L.LeakyReLU(0.2, name='relu1_c')(xc)\n",
        "    xc=L.Conv2D(64, kernel_size=3, padding='same', strides=1, name='conv2_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu2_c')(xc)\n",
        "    xc=L.MaxPool2D(pool_size=2, strides=2, name='pool1_c')(xc)\n",
        "    \n",
        "    xc=L.Conv2D(32, kernel_size=3, padding='same', strides=1, name='conv3_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu3_c')(xc)\n",
        "    xc=L.Conv2D(32, kernel_size=3, padding='same', strides=1, name='conv4_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu4_c')(xc)\n",
        "    xc=L.MaxPool2D(pool_size=2, strides=2, name='pool2_c')(xc)\n",
        "    \n",
        "    xc=L.Conv2D(16, kernel_size=3, padding='same', strides=1, name='conv5_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu5_c')(xc)\n",
        "    xc=L.Conv2D(16, kernel_size=3, padding='same', strides=1, name='conv6_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu6_c')(xc)\n",
        "    xc=L.MaxPool2D(pool_size=2, strides=2, name='pool3_c')(xc)\n",
        "    \n",
        "    xc=L.Flatten(name='flatten_c')(xc)\n",
        "    outputc=L.Dense(n_classes, activation='softmax', name='outputc')(xc)\n",
        "    #outputc=L.Softmax(name='outputc')(xc)\n",
        "    \n",
        "    '''\n",
        "        Creating binary classification model (a top/not a top)\n",
        "    '''\n",
        "    x=L.Conv2D(32, kernel_size=3, padding='same', strides=1, name='conv1_b')(inputs)\n",
        "    x=L.LeakyReLU(0.2, name='relu1_b')(x)\n",
        "    x=L.Conv2D(32, kernel_size=3, padding='same', strides=1, name='conv2_b')(x)\n",
        "    x=L.LeakyReLU(0.2, name='relu2_b')(x)\n",
        "    x=L.MaxPool2D(pool_size=2, strides=2, name='pool1_b')(x)\n",
        "    \n",
        "    x=L.Conv2D(16, kernel_size=3, padding='same', strides=1, name='conv3_b')(x)\n",
        "    x=L.LeakyReLU(0.2, name='relu3_b')(x)\n",
        "    x=L.Conv2D(16, kernel_size=3, padding='same', strides=1, name='conv4_b')(x)\n",
        "    x=L.LeakyReLU(0.2, name='relu4_b')(x)\n",
        "    x=L.MaxPool2D(pool_size=2, strides=2, name='pool2_b')(x)\n",
        "    \n",
        "    x=L.Flatten(name='flatten_b')(x)\n",
        "    outputb=L.Dense(1, activation='sigmoid', name='outputb')(x)\n",
        "    #outputb=L.Activation('sigmoid', name=\"outputb\")(x)\n",
        "\n",
        "    '''\n",
        "        Combining both models\n",
        "    '''\n",
        "    model=keras.Model(inputs=inputs, outputs=[outputc, outputb])\n",
        "    losses={'outputc':'categorical_crossentropy', 'outputb':'binary_crossentropy'}\n",
        "    loss_weights=[cl_weight, b_weight]\n",
        "    model.compile(optimizer=keras.optimizers.Adam(lr), \n",
        "                      loss=losses,\n",
        "                      loss_weights=loss_weights,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY707Bfw3YB-"
      },
      "source": [
        "def fine_tune(model, n_classes, cl_weight, b_weight, lr):\r\n",
        "    penultimate_layer=model.get_layer('flatten_c').output\r\n",
        "    outputc=L.Dense(n_classes, activation='softmax', name='outputc')(penultimate_layer)\r\n",
        "\r\n",
        "    outputb=model.get_layer('outputb').output\r\n",
        "    new_model=keras.Model(inputs=model.inputs,\r\n",
        "                        outputs=[outputc, outputb])\r\n",
        "    for layer in new_model.layers:\r\n",
        "        if(layer.name not in ['conv4_b', 'outputb', 'conv6_c', 'outputc']):\r\n",
        "            layer.trainable=False\r\n",
        "    losses={'outputc':'categorical_crossentropy', 'outputb':'binary_crossentropy'}\r\n",
        "    loss_weights=[cl_weight, b_weight]\r\n",
        "    new_model.compile(optimizer=keras.optimizers.Adam(lr), loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\r\n",
        "\r\n",
        "    return new_model"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3b09_gxAuA7"
      },
      "source": [
        "def train_model(model, n_epochs:int, x_train, y_trainc, y_trainb, validation_split):\n",
        "    history=model.fit(x=x_train, \n",
        "                      y={'outputc':y_trainc, 'outputb': y_trainb}, \n",
        "                      epochs=n_epochs, \n",
        "                      validation_split=0.1,\n",
        "                      shuffle=True,\n",
        "                      verbose=verbose)\n",
        "    return model"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-NFMEylIi8F"
      },
      "source": [
        "def synthesize_dataset(x_train, y_train, n):\r\n",
        "    labeldict={}\r\n",
        "    labeldict[0]=1\r\n",
        "    labeldict[1]=0\r\n",
        "    labeldict[2]=1\r\n",
        "    labeldict[3]=1\r\n",
        "    labeldict[4]=1\r\n",
        "    labeldict[5]=0\r\n",
        "    labeldict[6]=1\r\n",
        "    labeldict[7]=0\r\n",
        "    labeldict[8]=0\r\n",
        "    labeldict[9]=0\r\n",
        "\r\n",
        "    classes=[x for x in range(n)]\r\n",
        "    selected_indices=[]\r\n",
        "    unselected_indices=[]\r\n",
        "    for i in range(len(y_train)):\r\n",
        "        if(y_train[i] in classes):\r\n",
        "            selected_indices.append(i)\r\n",
        "        else:\r\n",
        "            unselected_indices.append(i)\r\n",
        "\r\n",
        "    x_train_new=np.delete(x_train, [unselected_indices], axis=0)\r\n",
        "    y_train=[y_train[i] for i in selected_indices]\r\n",
        "\r\n",
        "    y_trainb=[]\r\n",
        "    y_testb=[]\r\n",
        "    y_trainc=keras.utils.to_categorical(y_train)\r\n",
        "    #y_testc=keras.utils.to_categorical(y_test)\r\n",
        "    \r\n",
        "    for i in range(len(y_train)):\r\n",
        "        y_trainb.append(labeldict[y_train[i]])\r\n",
        "        \r\n",
        "    #for i in range(len(y_test)):\r\n",
        "    #    y_testb.append(labeldict[y_test[i]])\r\n",
        "    \r\n",
        "    return x_train_new, np.asarray(y_trainc), np.asarray(y_trainb)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtyWF1__3lhl"
      },
      "source": [
        "lr=0.0005\r\n",
        "epochs=5\r\n",
        "init_classes=3\r\n",
        "verbose=1"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwrcNzQZAuA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82850690-7ca1-4a9b-913f-47e1489628cf"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train=x_train.reshape((x_train.shape[0], 28,28,1))\n",
        "x_test=x_test.reshape((x_test.shape[0],28,28,1))\n",
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0\n",
        "\n",
        "#first iteration of training with 5 classes\n",
        "xt, ytc, ytb=synthesize_dataset(x_train, y_train, init_classes)\n",
        "model=create_model(n_classes=init_classes, input_dim=28, cl_weight=1.0, b_weight=1.5, lr=lr)\n",
        "train_model(model, epochs, xt, ytc, ytb, validation_split=0.1)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "507/507 [==============================] - 10s 18ms/step - loss: 0.5660 - outputc_loss: 0.2909 - outputb_loss: 0.1834 - outputc_accuracy: 0.8954 - outputb_accuracy: 0.9064 - val_loss: 0.1314 - val_outputc_loss: 0.0809 - val_outputb_loss: 0.0337 - val_outputc_accuracy: 0.9689 - val_outputb_accuracy: 0.9900\n",
            "Epoch 2/5\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 0.1082 - outputc_loss: 0.0766 - outputb_loss: 0.0210 - outputc_accuracy: 0.9751 - outputb_accuracy: 0.9941 - val_loss: 0.1087 - val_outputc_loss: 0.0775 - val_outputb_loss: 0.0208 - val_outputc_accuracy: 0.9750 - val_outputb_accuracy: 0.9939\n",
            "Epoch 3/5\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 0.1009 - outputc_loss: 0.0725 - outputb_loss: 0.0190 - outputc_accuracy: 0.9767 - outputb_accuracy: 0.9934 - val_loss: 0.1069 - val_outputc_loss: 0.0699 - val_outputb_loss: 0.0246 - val_outputc_accuracy: 0.9744 - val_outputb_accuracy: 0.9917\n",
            "Epoch 4/5\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 0.0829 - outputc_loss: 0.0580 - outputb_loss: 0.0166 - outputc_accuracy: 0.9810 - outputb_accuracy: 0.9950 - val_loss: 0.1021 - val_outputc_loss: 0.0723 - val_outputb_loss: 0.0199 - val_outputc_accuracy: 0.9750 - val_outputb_accuracy: 0.9928\n",
            "Epoch 5/5\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 0.0713 - outputc_loss: 0.0536 - outputb_loss: 0.0118 - outputc_accuracy: 0.9823 - outputb_accuracy: 0.9965 - val_loss: 0.1010 - val_outputc_loss: 0.0692 - val_outputb_loss: 0.0213 - val_outputc_accuracy: 0.9744 - val_outputb_accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f9a86bff438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AGVqnq89WGX",
        "outputId": "37763e2b-58c8-49d8-b22e-8aa441066557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#second iteration of training with 9 classes\r\n",
        "xt, ytc, ytb=synthesize_dataset(x_train, y_train, init_classes+7)\r\n",
        "ftmodel=fine_tune(model, n_classes=init_classes+7, cl_weight=1, b_weight=1, lr=0.001)\r\n",
        "train_model(ftmodel, epochs, xt, ytc, ytb, validation_split=0.1)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.8941 - outputc_loss: 0.8030 - outputb_loss: 0.0911 - outputc_accuracy: 0.7280 - outputb_accuracy: 0.9684 - val_loss: 0.4324 - val_outputc_loss: 0.3990 - val_outputb_loss: 0.0334 - val_outputc_accuracy: 0.8480 - val_outputb_accuracy: 0.9898\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 18s 11ms/step - loss: 0.4138 - outputc_loss: 0.3795 - outputb_loss: 0.0344 - outputc_accuracy: 0.8583 - outputb_accuracy: 0.9899 - val_loss: 0.3895 - val_outputc_loss: 0.3633 - val_outputb_loss: 0.0262 - val_outputc_accuracy: 0.8663 - val_outputb_accuracy: 0.9910\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 18s 10ms/step - loss: 0.3792 - outputc_loss: 0.3521 - outputb_loss: 0.0271 - outputc_accuracy: 0.8691 - outputb_accuracy: 0.9918 - val_loss: 0.3935 - val_outputc_loss: 0.3657 - val_outputb_loss: 0.0278 - val_outputc_accuracy: 0.8648 - val_outputb_accuracy: 0.9922\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 18s 11ms/step - loss: 0.3474 - outputc_loss: 0.3253 - outputb_loss: 0.0221 - outputc_accuracy: 0.8794 - outputb_accuracy: 0.9933 - val_loss: 0.3859 - val_outputc_loss: 0.3630 - val_outputb_loss: 0.0229 - val_outputc_accuracy: 0.8630 - val_outputb_accuracy: 0.9923\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 18s 11ms/step - loss: 0.3368 - outputc_loss: 0.3155 - outputb_loss: 0.0213 - outputc_accuracy: 0.8817 - outputb_accuracy: 0.9938 - val_loss: 0.3679 - val_outputc_loss: 0.3365 - val_outputb_loss: 0.0314 - val_outputc_accuracy: 0.8770 - val_outputb_accuracy: 0.9882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f9a88626f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    }
  ]
}
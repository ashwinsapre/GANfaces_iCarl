{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "iCarl_main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinsapre/GANfaces_iCarl/blob/main/iCarl_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y73F_4X-AuAy"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import keras.layers as L\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.applications import DenseNet121\n",
        "from keras.applications import VGG16\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3d2b1v4Nik8",
        "outputId": "2dcf2125-4ce8-4871-cc6b-357705600b4b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VttqVxphAuA6"
      },
      "source": [
        " For multi-task learning, branching NN out\n",
        "- one branch predicts the class of FashionMNIST object (classification)\n",
        "- other branch predicts whether the object is a \"top\" or not (0/1 output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-eX21QAuA6"
      },
      "source": [
        "def create_model(n_classes, input_dim, cl_weight, b_weight, lr):\n",
        "    '''\n",
        "        Creating categorical classification model\n",
        "    '''\n",
        "    \n",
        "    inputs=L.Input((input_dim,input_dim,1), name='input_layer_common')\n",
        "    \n",
        "    xc=L.Conv2D(64, kernel_size=3, padding='same', strides=1, name='conv1_c')(inputs)\n",
        "    xc=L.LeakyReLU(0.2, name='relu1_c')(xc)\n",
        "    xc=L.Conv2D(64, kernel_size=3, padding='same', strides=1, name='conv2_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu2_c')(xc)\n",
        "    xc=L.MaxPool2D(pool_size=2, strides=2)(xc)\n",
        "    \n",
        "    xc=L.Conv2D(32, kernel_size=3, padding='same', strides=1, name='conv3_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu3_c')(xc)\n",
        "    xc=L.Conv2D(32, kernel_size=3, padding='same', strides=1, name='conv4_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu4_c')(xc)\n",
        "    xc=L.MaxPool2D(pool_size=2, strides=2)(xc)\n",
        "    \n",
        "    xc=L.Conv2D(16, kernel_size=3, padding='same', strides=1, name='conv5_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu5_c')(xc)\n",
        "    xc=L.Conv2D(16, kernel_size=3, padding='same', strides=1, name='conv6_c')(xc)\n",
        "    xc=L.LeakyReLU(0.2, name='relu6_c')(xc)\n",
        "    xc=L.MaxPool2D(pool_size=2, strides=2)(xc)\n",
        "    \n",
        "    xc=L.Flatten(name='flatten_c')(xc)\n",
        "    xc=L.Dense(n_classes)(xc)\n",
        "    outputc=L.Softmax(name='outputc')(xc)\n",
        "    \n",
        "    '''\n",
        "        Creating binary classification model (a top/not a top)\n",
        "    '''\n",
        "    x=L.Conv2D(32, kernel_size=3, padding='same', strides=1)(inputs)\n",
        "    x=L.LeakyReLU(0.2)(x)\n",
        "    x=L.Conv2D(32, kernel_size=3, padding='same', strides=1)(x)\n",
        "    x=L.LeakyReLU(0.2)(x)\n",
        "    x=L.MaxPool2D(pool_size=2, strides=2)(x)\n",
        "    \n",
        "    x=L.Conv2D(16, kernel_size=3, padding='same', strides=1)(x)\n",
        "    x=L.LeakyReLU(0.2)(x)\n",
        "    x=L.Conv2D(16, kernel_size=3, padding='same', strides=1)(x)\n",
        "    x=L.LeakyReLU(0.2)(x)\n",
        "    x=L.MaxPool2D(pool_size=2, strides=2)(x)\n",
        "    \n",
        "    x=L.Flatten(name='flatten_b')(x)\n",
        "    outputb=L.Dense(1, activation='sigmoid', name='outputb')(x)\n",
        "    #outputb=L.Activation('sigmoid', name=\"outputb\")(x)\n",
        "\n",
        "    '''\n",
        "        Combining both models\n",
        "    '''\n",
        "    model=keras.Model(inputs=inputs, outputs=[outputc, outputb])\n",
        "    losses={'outputc':'categorical_crossentropy', 'outputb':'binary_crossentropy'}\n",
        "    loss_weights=[cl_weight, b_weight]\n",
        "    model.compile(optimizer=keras.optimizers.Adam(lr), \n",
        "                      loss=losses,\n",
        "                      loss_weights=loss_weights,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY707Bfw3YB-"
      },
      "source": [
        "def fine_tune(model, n_classes, cl_weight, b_weight, lr):\r\n",
        "    penultimate_layer=model.get_layer('flatten_c').output\r\n",
        "    penultimate_layer=L.Dense(n_classes)(penultimate_layer)\r\n",
        "    new_outputc=L.Softmax(name='new_outputc')(penultimate_layer)\r\n",
        "\r\n",
        "    outputb=model.get_layer('outputb').output\r\n",
        "    new_model=keras.Model(inputs=model.inputs,\r\n",
        "                        outputs=[new_outputc, outputb])\r\n",
        "    losses={'outputc':'categorical_crossentropy', 'outputb':'binary_crossentropy'}\r\n",
        "    loss_weights=[cl_weight, b_weight]\r\n",
        "    new_model.compile(optimizer=keras.optimizers.Adam(lr), loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\r\n",
        "\r\n",
        "    return new_model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3b09_gxAuA7"
      },
      "source": [
        "def train_model(model, n_epochs:int, x_train, y_trainc, y_trainb, validation_split):\n",
        "    history=model.fit(x=x_train, \n",
        "                      y={'outputc':y_trainc, 'outputb': y_trainb}, \n",
        "                      epochs=n_epochs, \n",
        "                      validation_split=0.1,\n",
        "                      shuffle=True,\n",
        "                      verbose=2)\n",
        "    return model"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd5OfDiIAuA7"
      },
      "source": [
        "def calc_feature_vectors(model, images):\n",
        "    #extract feature vector from a layer of ALREADY-TRAINED model\n",
        "    #size of feature vector=784\n",
        "    feature_model=keras.Model(inputs=model.inputs, outputs=model.get_layer(\"flatten\").output)\n",
        "    feature_vectors=feature_model.predict(images)\n",
        "    norms=np.linalg.norm(feature_vectors, keepdims=True, axis=1)\n",
        "    feature_vectors=feature_vectors/norms\n",
        "    return feature_vectors"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jymSn4mRtO5H"
      },
      "source": [
        "def create_exemplar_set(mem_size, n_classes, feature_vectors, labels, reconstruct=False):\r\n",
        "    per_class=mem_size//n_classes\r\n",
        "\r\n",
        "    class_vectors={}\r\n",
        "    mean_class_vectors={}\r\n",
        "    class_vectors_distances={}\r\n",
        "\r\n",
        "    #init dicts\r\n",
        "    for i in range(n_classes):\r\n",
        "      class_vectors[i]=[]\r\n",
        "      mean_class_vectors[i]=[]\r\n",
        "      class_vectors_distances[i]=[]\r\n",
        "    \r\n",
        "    #vectors belonging to class i go in the list in key i of class_vectors\r\n",
        "    for i in range(len(labels)):\r\n",
        "      class_vectors[labels[i]].append(feature_vectors[i])\r\n",
        "\r\n",
        "    #calculate mean class vectors by summing all vectors per class and diving by length\r\n",
        "    for i in range(n_classes):\r\n",
        "      mean_class_vectors[i]=np.sum(class_vectors[i], axis=0)/len(class_vectors[i])\r\n",
        "    \r\n",
        "    #calculating distances from mean\r\n",
        "    for i in range(len(labels)):\r\n",
        "      class_vectors_distances[labels[i]].append(np.linalg.norm(mean_class_vectors[labels[i]] - feature_vectors[i]))\r\n",
        "\r\n",
        "    #sorting vectors by their corresponding distances from class means\r\n",
        "    for i in range(n_classes):\r\n",
        "      class_vectors_distances[i], class_vectors[i] = (list(t) for t in zip(*sorted(zip(class_vectors_distances[i], class_vectors[i]))))\r\n",
        "\r\n",
        "    exemplars_x = []\r\n",
        "    exemplars_y = []\r\n",
        "\r\n",
        "    #choose 'per_class' number of vectors\r\n",
        "    for i in range(n_classes):\r\n",
        "      exemplars_x.append(class_vectors[i][:per_class])\r\n",
        "      exemplars_y+= per_class*[i]\r\n",
        "\r\n",
        "    return exemplars_x, exemplars_y"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Wu1QlhAuA7"
      },
      "source": [
        "def classify(X, mean_class_vectors, n_classes):\n",
        "    #image embedding created\n",
        "    image_vector=calc_feature_vectors(model, X)\n",
        "    #distance to all mean vectors calculated\n",
        "    distances=[]\n",
        "    indices=[x for x in range(n_classes)]\n",
        "    #sort class values by their corresponding distances\n",
        "    for i in range(n_classes):\n",
        "      distances.append(np.linalg.norm(mean_class_vectors[i] - image_vector))\n",
        "    distances, indices = (list(t) for t in zip(*sorted(zip(distances, indices))))\n",
        "    #return the class with the least distance\n",
        "    return indices[0]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l48ckkJAuA8"
      },
      "source": [
        "def transform_outputs(y_train, y_test):\n",
        "    labeldict={}\n",
        "    labeldict[0]=1\n",
        "    labeldict[1]=0\n",
        "    labeldict[2]=1\n",
        "    labeldict[3]=1\n",
        "    labeldict[4]=1\n",
        "    labeldict[5]=0\n",
        "    labeldict[6]=1\n",
        "    labeldict[7]=0\n",
        "    labeldict[8]=0\n",
        "    labeldict[9]=0\n",
        "    \n",
        "    y_trainb=[]\n",
        "    y_testb=[]\n",
        "    y_trainc=keras.utils.to_categorical(y_train)\n",
        "    y_testc=keras.utils.to_categorical(y_test)\n",
        "    \n",
        "    for i in range(len(y_train)):\n",
        "        y_trainb.append(labeldict[y_train[i]])\n",
        "        \n",
        "    for i in range(len(y_test)):\n",
        "        y_testb.append(labeldict[y_test[i]])\n",
        "    \n",
        "    return y_trainc, y_testc, np.asarray(y_trainb), np.asarray(y_testb)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwrcNzQZAuA8"
      },
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train=x_train.reshape((x_train.shape[0], 28,28,1))\n",
        "x_test=x_test.reshape((x_test.shape[0],28,28,1))\n",
        "y_trainc, y_testc, y_trainb, y_testb=transform_outputs(y_train, y_test)\n",
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0\n",
        "\n",
        "#np.savetxt(\"ytrain_transformed.csv\", y_train, delimiter=',')\n",
        "#np.savetxt(\"ytest_transformed.csv\", y_test, delimiter=',')\n",
        "    \n",
        "#y_train=np.loadtxt(open(\"ytrain_transformed.csv\", \"rb\"), delimiter=',')\n",
        "#y_test=np.loadtxt(open(\"ytest_transformed.csv\", \"rb\"), delimiter=',')\n",
        "    \n",
        "model=create_model(n_classes=10, input_dim=28, cl_weight=1.0, b_weight=1.5, lr=0.0005)\n",
        "    \n",
        "train_model(model, 10, x_train, y_trainc, y_trainb, validation_split=0.1)\n",
        "model.save(\"trainedmodel.h5\")\n",
        "#-----------------------------------------------------------------------#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpDZ9X6UFnVh",
        "outputId": "17b828f3-e12e-479a-e003-db5d4104baff"
      },
      "source": [
        "'''\r\n",
        "    TESTING CELL\r\n",
        "'''\r\n",
        "ftmodel=fine_tune(model, n_classes=11, cl_weight=1, b_weight=1, lr=0.001)\r\n",
        "ftmodel.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_layer_common (InputLayer) [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_c (Conv2D)                (None, 28, 28, 64)   640         input_layer_common[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "relu1_c (LeakyReLU)             (None, 28, 28, 64)   0           conv1_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2_c (Conv2D)                (None, 28, 28, 64)   36928       relu1_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu2_c (LeakyReLU)             (None, 28, 28, 64)   0           conv2_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_80 (MaxPooling2D) (None, 14, 14, 64)   0           relu2_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3_c (Conv2D)                (None, 14, 14, 32)   18464       max_pooling2d_80[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "relu3_c (LeakyReLU)             (None, 14, 14, 32)   0           conv3_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 28, 28, 32)   320         input_layer_common[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_c (Conv2D)                (None, 14, 14, 32)   9248        relu3_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_140 (LeakyReLU)     (None, 28, 28, 32)   0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "relu4_c (LeakyReLU)             (None, 14, 14, 32)   0           conv4_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 28, 28, 32)   9248        leaky_re_lu_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_81 (MaxPooling2D) (None, 7, 7, 32)     0           relu4_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_141 (LeakyReLU)     (None, 28, 28, 32)   0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_c (Conv2D)                (None, 7, 7, 16)     4624        max_pooling2d_81[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_83 (MaxPooling2D) (None, 14, 14, 32)   0           leaky_re_lu_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "relu5_c (LeakyReLU)             (None, 7, 7, 16)     0           conv5_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 14, 14, 16)   4624        max_pooling2d_83[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv6_c (Conv2D)                (None, 7, 7, 16)     2320        relu5_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_142 (LeakyReLU)     (None, 14, 14, 16)   0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "relu6_c (LeakyReLU)             (None, 7, 7, 16)     0           conv6_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 14, 14, 16)   2320        leaky_re_lu_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_82 (MaxPooling2D) (None, 3, 3, 16)     0           relu6_c[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_143 (LeakyReLU)     (None, 14, 14, 16)   0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_c (Flatten)             (None, 144)          0           max_pooling2d_82[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_84 (MaxPooling2D) (None, 7, 7, 16)     0           leaky_re_lu_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 11)           1595        flatten_c[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_b (Flatten)             (None, 784)          0           max_pooling2d_84[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "new_outputc (Softmax)           (None, 11)           0           dense_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "outputb (Dense)                 (None, 1)            785         flatten_b[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 91,116\n",
            "Trainable params: 91,116\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
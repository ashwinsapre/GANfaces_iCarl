{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import keras.layers as L\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.applications import DenseNet121\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exemplar_set(size, images, trained_model):\n",
    "    #'images' has images all of class=y\n",
    "    exemplars=[]\n",
    "    for i in images:\n",
    "        exemplars.append(calc_feature_vector(i, trained_model, layer_index))\n",
    "    chosen_exemplars=exemplars[:size]\n",
    "    mean_exemplar=sum(exemplars)/len(images)\n",
    "    return chosen_exemplars, mean_exemplar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For multi-task learning, branching NN out\n",
    "- one branch predicts the class of FashionMNIST object (classification)\n",
    "- other branch predicts whether the object is a \"top\" or not (0/1 output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes, input_dim):\n",
    "    '''\n",
    "        Creating categorical classification model\n",
    "    '''\n",
    "    \n",
    "    inputs=L.Input((input_dim,input_dim,1))\n",
    "    \n",
    "    #xc=L.Conv2D(64, kernel_size=3, padding='same', strides=1)(inputs)\n",
    "    #xc=L.LeakyReLU(0.2)(xc)\n",
    "    #xc=L.Conv2D(64, kernel_size=3, padding='same', strides=1)(xc)\n",
    "    #xc=L.LeakyReLU(0.2)(xc)\n",
    "    #xc=L.MaxPool2D(pool_size=2, strides=2)(xc)\n",
    "    \n",
    "    xc=L.Conv2D(32, kernel_size=3, padding='same', strides=1)(inputs)\n",
    "    xc=L.LeakyReLU(0.2)(xc)\n",
    "    xc=L.Conv2D(32, kernel_size=3, padding='same', strides=1)(xc)\n",
    "    xc=L.LeakyReLU(0.2)(xc)\n",
    "    xc=L.MaxPool2D(pool_size=2, strides=2)(xc)\n",
    "    \n",
    "    xc=L.Conv2D(16, kernel_size=3, padding='same', strides=1)(xc)\n",
    "    xc=L.LeakyReLU(0.2)(xc)\n",
    "    xc=L.Conv2D(16, kernel_size=3, padding='same', strides=1)(xc)\n",
    "    xc=L.LeakyReLU(0.2)(xc)\n",
    "    xc=L.MaxPool2D(pool_size=2, strides=2)(xc)\n",
    "    \n",
    "    xc=L.Flatten()(xc)\n",
    "    xc=L.Dense(n_classes)(xc)\n",
    "    outputc=L.Softmax(name='outputc')(xc)\n",
    "    \n",
    "    '''\n",
    "        Creating binary classification model (a top/not a top)\n",
    "    '''\n",
    "    \n",
    "    x=L.LeakyReLU(0.2)(inputs)\n",
    "    x=L.Conv2D(32, kernel_size=3, padding='same', strides=1)(x)\n",
    "    x=L.LeakyReLU(0.2)(x)\n",
    "    x=L.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    x=L.Conv2D(16, kernel_size=3, padding='same', strides=1)(x)\n",
    "    x=L.LeakyReLU(0.2)(x)\n",
    "    x=L.Conv2D(16, kernel_size=3, padding='same', strides=1)(x)\n",
    "    x=L.LeakyReLU(0.2)(x)\n",
    "    x=L.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    x=L.Flatten()(x)\n",
    "    outputb=L.Dense(1, activation='sigmoid', name='outputb')(x)\n",
    "    #outputb=L.Activation('sigmoid', name=\"outputb\")(x)\n",
    "\n",
    "    '''\n",
    "        Combining both models\n",
    "    '''\n",
    "    model=keras.Model(inputs=inputs, outputs=[outputc, outputb])\n",
    "    losses={'outputc':'categorical_crossentropy', 'outputb':'binary_crossentropy'}\n",
    "    loss_weights=[1.0, 1.2]\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.02), \n",
    "                      loss=losses,\n",
    "                      loss_weights=loss_weights,\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, n_epochs:int, x_train, y_trainc, y_trainb):\n",
    "    model.fit(x=x_train, y={'outputc':y_trainc, 'outputb': y_trainb}, epochs=n_epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_vector(image, model, layer_index):\n",
    "    #extract feature vector from a layer of ALREADY-TRAINED model\n",
    "    extractor=keras.Model(model.inputs(), [model.layers[layer_index].output])\n",
    "    vector=extractor(image)\n",
    "    #divide vector by norm\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, mean_exemplar_sets):    \n",
    "    image_vector=calc_feature_vector(X)\n",
    "    #exemplar set closest to X feature map is chosen\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_outputs(y_train, y_test):\n",
    "    labeldict={}\n",
    "    labeldict[0]=1\n",
    "    labeldict[1]=0\n",
    "    labeldict[2]=1\n",
    "    labeldict[3]=1\n",
    "    labeldict[4]=1\n",
    "    labeldict[5]=0\n",
    "    labeldict[6]=1\n",
    "    labeldict[7]=0\n",
    "    labeldict[8]=0\n",
    "    labeldict[9]=0\n",
    "    \n",
    "    y_trainb=[]\n",
    "    y_testb=[]\n",
    "    y_trainc=keras.utils.to_categorical(y_train)\n",
    "    y_testc=keras.utils.to_categorical(y_test)\n",
    "    \n",
    "    for i in range(len(y_train)):\n",
    "        y_trainb.append(labeldict[y_train[i]])\n",
    "        \n",
    "    for i in range(len(y_test)):\n",
    "        y_testb.append(labeldict[y_test[i]])\n",
    "    \n",
    "    return y_trainc, y_testc, np.asarray(y_trainb), np.asarray(y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    (x_train, y_train), (x_test, y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
    "    x_train=x_train.reshape((x_train.shape[0], 28,28,1))\n",
    "    x_test=x_test.reshape((x_test.shape[0],28,28,1))\n",
    "    y_trainc, y_testc, y_trainb, y_testb=transform_outputs(y_train, y_test)\n",
    "    x_train=x_train/255.0\n",
    "    x_test=x_test/255.0\n",
    "    \n",
    "    #np.savetxt(\"ytrain_transformed.csv\", y_train, delimiter=',')\n",
    "    #np.savetxt(\"ytest_transformed.csv\", y_test, delimiter=',')\n",
    "    \n",
    "    #y_train=np.loadtxt(open(\"ytrain_transformed.csv\", \"rb\"), delimiter=',')\n",
    "    #y_test=np.loadtxt(open(\"ytest_transformed.csv\", \"rb\"), delimiter=',')\n",
    "    \n",
    "    model=create_model(10,28)\n",
    "    \n",
    "    train_model(model, 5, x_train, y_trainc, y_trainb)\n",
    "    \n",
    "#-----------------------------------------------------------------------#\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
